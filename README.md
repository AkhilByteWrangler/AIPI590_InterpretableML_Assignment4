# AIPI 590 - XAI | Assignment #04

## Interpretable Machine Learning Models: FIGS, RF+/MDI+, and Hierarchical Shrinkage

### Author: Akhil Chintalapati

### Description:
This repository contains the implementation of three interpretable machine learning models—**FIGS**, **RF+/MDI+**, and **Hierarchical Shrinkage**—as part of the AIPI 590 course (Explainable AI) Assignment #04. The models are implemented using the `imodels` library on a dataset for species classification (Palmer Penguins dataset).

The objective of this assignment is to demonstrate the use of **interpretable models** that provide insights into how predictions are made, while still maintaining strong predictive performance.

### Models Used:

#### 1. **FIGS** (Fast Interpretable Greedy-tree Sums):
   - **Explanation**: FIGS is a decision-tree-based method designed to create a sum of small decision trees to explain predictions in a clear, concise, and interpretable way. Each small tree adds to the decision process, which makes FIGS faster and more interpretable than complex black-box models.
   - **Usage in Assignment**: In this notebook, FIGS is trained on the dataset to predict the species. The resulting model is highly interpretable because of the clear decision rules generated by the trees.
   - **Citation**: Tan, Y. S., et al. (2023). *Fast interpretable greedy-tree sums (FIGS)*. ArXiv preprint. 
   - [FIGS Documentation](https://csinva.io/imodels/figs.html)

#### 2. **RF+/MDI+** (Random Forest with MDI+ Feature Importance):
   - **Explanation**: RF+/MDI+ extends the traditional random forest framework to enhance feature importance measurements. It improves the way feature importance is calculated by considering both individual decision trees and the interactions between features, making the feature importance results more robust and reliable.
   - **Usage in Assignment**: The RF+/MDI+ model is used to analyze the significance of each feature (e.g., bill length, flipper length) in predicting the species. The `MDI+` feature importance scores are visualized to highlight the most influential features.
   - **Citation**: Agarwal, A., et al. (2023). *MDI+: A flexible random forest-based feature importance framework*. ArXiv preprint.
   - [MDI+ Documentation](https://csinva.io/imodels/mdi_plus.html)

#### 3. **Hierarchical Shrinkage**:
   - **Explanation**: Hierarchical Shrinkage is an advanced method that improves decision tree models by balancing the need for accurate predictions and interpretability. It uses hierarchical regularization to prevent overfitting while still maintaining interpretable decision rules. This method shrinks complex decision rules into simpler, more generalizable forms.
   - **Usage in Assignment**: Hierarchical Shrinkage is used to build a decision tree model on the dataset with a limited number of leaf nodes (to maintain interpretability). The tree is visualized to show the decision-making process.
   - **Citation**: Agarwal, A., et al. (2022). *Hierarchical Shrinkage: Improving the accuracy and interpretability of tree-based models*. In International Conference on Machine Learning.
   - [Hierarchical Shrinkage Documentation](https://csinva.io/imodels/shrinkage.html)

### Running the Notebook:
You can run the notebook in Google Colab by clicking the button below:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AkhilByteWrangler/AIPI590_InterpretableML_Assignment4/blob/main/Interpretable_ML_Models_AIPI590.ipynb)

### Installation Instructions:

1. **Clone the Repository**:
   - Clone this repository to your local machine using the following command:
     ```bash
     git clone https://github.com/AkhilByteWrangler/AIPI590_InterpretableML_Assignment4.git
     ```

2. **Running the Code**:
   - You can either run the notebook locally or in Google Colab by following the provided link above. The models will automatically train on the dataset and display interpretable results.

### Evaluation Metrics:
- Each model is evaluated based on **accuracy**, **precision**, **recall**, and **F1-score**.
- The confusion matrix for each model is also displayed to give a clear breakdown of prediction performance across the different species classes.

### Visualization:
- **FIGS** and **Hierarchical Shrinkage** models include **decision tree visualizations** that display the learned decision rules.
- **RF+/MDI+** model includes a **feature importance plot** that highlights the most important features used in classification.

### Conclusion:
This assignment demonstrates the power of interpretable machine learning models in making predictions that are both accurate and explainable. By using decision tree-based models like FIGS, RF+/MDI+, and Hierarchical Shrinkage, we can gain insights into how the models arrive at their predictions while avoiding the "black-box" nature of more complex models like deep neural networks.

### License:
This project is licensed for academic and non-commercial use only. See the [LICENSE](LICENSE) file for more details.
